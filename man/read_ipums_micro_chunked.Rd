% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/micro_read_chunked.r
\name{read_ipums_micro_chunked}
\alias{read_ipums_micro_chunked}
\alias{read_ipums_micro_list_chunked}
\title{Read data from an IPUMS extract by chunk}
\usage{
read_ipums_micro_chunked(
  ddi,
  callback,
  chunk_size = 10000,
  vars = NULL,
  data_file = NULL,
  verbose = TRUE,
  var_attrs = c("val_labels", "var_label", "var_desc"),
  lower_vars = FALSE
)

read_ipums_micro_list_chunked(
  ddi,
  callback,
  chunk_size = 10000,
  vars = NULL,
  data_file = NULL,
  verbose = TRUE,
  var_attrs = c("val_labels", "var_label", "var_desc"),
  lower_vars = FALSE
)
}
\arguments{
\item{ddi}{Either a path to a DDI .xml file downloaded from
\href{https://www.ipums.org/}{IPUMS}, or an
\link{ipums_ddi} object parsed by \code{\link[=read_ipums_ddi]{read_ipums_ddi()}}.}

\item{callback}{An \link{ipums_callback} object, or a function
that will be converted to an \code{IpumsSideEffectCallback} object.}

\item{chunk_size}{Integer number of observations to
read per chunk. Higher values use more RAM, but
typically result in faster processing. Defaults to 10,000.}

\item{vars}{Names of variables to include in the output. Accepts a
vector of names or a \link[tidyselect:language]{selection helper}.
If \code{NULL}, includes all variables in the file.

For hierarchical data, the \code{RECTYPE} variable is always included even if
unspecified.}

\item{data_file}{Path to the data (.gz) file associated with
the provided \code{ddi} file. By default, looks for the data file in the same
directory as the DDI file. If the data file has been moved, specify
its location here.}

\item{verbose}{Logical indicating whether to print progress information
to the console.}

\item{var_attrs}{Variable attributes from the DDI to add to the columns of
the output data. Defaults to all available attributes (\code{"val_labels"},
\code{"var_label"}, and \code{"var_desc"}). See \code{\link[=set_ipums_var_attributes]{set_ipums_var_attributes()}}
for more details.}

\item{lower_vars}{If reading a DDI from a file,
a logical indicating whether to convert variable names to lowercase.
Defaults to \code{FALSE} for consistency with IPUMS conventions.

This argument will be ignored if argument \code{ddi} is
an \link{ipums_ddi} object. Use \code{\link[=read_ipums_ddi]{read_ipums_ddi()}} to convert variable
names to lowercase when reading a DDI file.

Note that if reading in chunks from a .csv or
.csv.gz file, the callback function will be called \emph{before} variable names
are converted to lowercase, and thus should reference uppercase variable
names.}
}
\value{
Depends on the provided callback object. See \link{ipums_callback}.
}
\description{
Read a microdata dataset downloaded from the IPUMS extract system in chunks.

Use these functions to read a file that is too large to store in memory
at a single time. The file is processed in chunks of a given size, with a
provided callback function applied to each chunk.

See \code{\link[=read_ipums_micro_yield]{read_ipums_micro_yield()}} for an alternate approach to reading large
files.

\code{read_ipums_micro_chunked()} and \code{read_ipums_micro_list_chunked()} differ
in their handling of extracts that contain multiple record types.
See details.
}
\details{
IPUMS microdata extracts use two associated files: a DDI codebook (.xml)
file and a fixed-width data file. The DDI file contains metadata about the
associated data file which are used to parse its data correctly upon load.

Data are loaded with value label and variable label information
attached to each column, where appropriate. See
\code{\link[haven:labelled]{haven::labelled()}}.
\subsection{Data structures}{

Files from IPUMS projects that contain data for multiple types of records
(e.g. household records and person records) may be either rectangular
or hierarchical.

Rectangular data are transformed such that each row of data
represents only one type of record. For instance, each row will represent
a person record, and all household-level information for that person will
be included in the same row.

Hierarchical data have records of
different types interspersed in a single file. For instance, a household
record will be included in its own row followed by the person records
associated with that household.

Hierarchical data can be read in two different formats:
\itemize{
\item \code{read_ipums_micro_chunked()} reads each chunk of data into a
\code{\link[tibble:tbl_df-class]{tibble}} where each row represents a single record,
regardless of record type. Variables that do not apply to a particular
record type will be filled with \code{NA} in rows of that record type. For
instance, a person-specific variable will be missing in all rows
associated with household records. The provided \code{callback} function should
therefore operate on a \code{tibble} object.
\item \code{read_ipums_micro_list_chunked()} reads each chunk of data into a list of
\code{tibble} objects, where each list element contains
only one record type. Each list element is named with its corresponding
record type. The provided \code{callback} function should therefore operate
on a list object.
}

Callback functions should include both a data and position argument. See
examples.
}
}
\examples{
# Select Minnesotan cases from CPS example (Note you can also accomplish
# this and avoid having to even download a huge file using the "Select Cases"
# functionality of the IPUMS extract system)
mn_only <- read_ipums_micro_chunked(
  ipums_example("cps_00006.xml"),
  IpumsDataFrameCallback$new(function(x, pos) {
    x[x$STATEFIP == 27, ]
  }),
  chunk_size = 1000 # Generally you want this larger, but this example is a small file
)

# Tabulate INCTOT average by state without storing full dataset in memory
library(dplyr)
inc_by_state <- read_ipums_micro_chunked(
  ipums_example("cps_00006.xml"),
  IpumsDataFrameCallback$new(function(x, pos) {
    x \%>\%
      mutate(
        INCTOT = lbl_na_if(
          INCTOT, ~.lbl \%in\% c("Missing.", "N.I.U. (Not in Universe)."))
        ) \%>\%
      filter(!is.na(INCTOT)) \%>\%
      group_by(STATEFIP = as_factor(STATEFIP)) \%>\%
      summarize(INCTOT_SUM = sum(INCTOT), n = n(), .groups = "drop")
  }),
  chunk_size = 1000 # Generally you want this larger, but this example is a small file
) \%>\%
group_by(STATEFIP) \%>\%
summarize(avg_inc = sum(INCTOT_SUM) / sum(n))

# x will be a list when using `read_ipums_micro_list_chunked()`
read_ipums_micro_list_chunked(
  ipums_example("cps_00010.xml"),
  IpumsSideEffectCallback$new(function(x, pos) {
    print(paste0(nrow(x$PERSON), " persons and ", nrow(x$HOUSEHOLD), " households in this chunk."))
  }),
  chunk_size = 1000 # Generally you want this larger, but this example is a small file
)

# Using the biglm package, you can even run a regression without storing
# the full dataset in memory
library(dplyr)
if (require(biglm)) {
  lm_results <- read_ipums_micro_chunked(
    ipums_example("cps_00015.xml"),
    IpumsBiglmCallback$new(
      INCTOT ~ AGE + HEALTH, # Simple regression (may not be very useful)
      function(x, pos) {
        x \%>\%
        mutate(
          INCTOT = lbl_na_if(
            INCTOT, ~.lbl \%in\% c("Missing.", "N.I.U. (Not in Universe).")
          ),
          HEALTH = as_factor(HEALTH)
        )
    }),
    chunk_size = 1000 # Generally you want this larger, but this example is a small file
  )
  summary(lm_results)
}

}
\seealso{
Other ipums_read: 
\code{\link{ipums_list_files}()},
\code{\link{read_ipums_ddi}()},
\code{\link{read_ipums_micro_yield}()},
\code{\link{read_ipums_micro}()},
\code{\link{read_ipums_sf}()},
\code{\link{read_nhgis_codebook}()},
\code{\link{read_nhgis}()}
}
\concept{ipums_read}
